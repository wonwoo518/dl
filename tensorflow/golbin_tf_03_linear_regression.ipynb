{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X_1:0\", dtype=float32)\n",
      "Tensor(\"Y_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.2833 [ 0.68732405] [ 1.12814689]\n",
      "1 0.31798 [ 0.52789617] [ 1.02758789]\n",
      "2 0.15554 [ 0.55749124] [ 1.01091182]\n",
      "3 0.146392 [ 0.56613475] [ 0.98573297]\n",
      "4 0.139417 [ 0.57678246] [ 0.96213245]\n",
      "5 0.132795 [ 0.58693254] [ 0.93899298]\n",
      "6 0.126487 [ 0.596865] [ 0.91642135]\n",
      "7 0.120479 [ 0.60655576] [ 0.89439106]\n",
      "8 0.114756 [ 0.61601394] [ 0.87289053]\n",
      "9 0.109305 [ 0.62524474] [ 0.85190684]\n",
      "10 0.104113 [ 0.63425356] [ 0.83142757]\n",
      "11 0.0991672 [ 0.6430459] [ 0.81144065]\n",
      "12 0.0944567 [ 0.65162677] [ 0.79193413]\n",
      "13 0.08997 [ 0.66000152] [ 0.77289659]\n",
      "14 0.0856963 [ 0.6681748] [ 0.75431669]\n",
      "15 0.0816257 [ 0.67615163] [ 0.7361834]\n",
      "16 0.0777484 [ 0.68393677] [ 0.71848607]\n",
      "17 0.0740553 [ 0.6915347] [ 0.70121413]\n",
      "18 0.0705376 [ 0.69894999] [ 0.6843574]\n",
      "19 0.067187 [ 0.70618707] [ 0.66790593]\n",
      "20 0.0639956 [ 0.7132501] [ 0.65184993]\n",
      "21 0.0609557 [ 0.72014338] [ 0.63617992]\n",
      "22 0.0580603 [ 0.72687095] [ 0.62088662]\n",
      "23 0.0553024 [ 0.73343676] [ 0.60596091]\n",
      "24 0.0526755 [ 0.7398448] [ 0.59139401]\n",
      "25 0.0501734 [ 0.74609876] [ 0.57717729]\n",
      "26 0.0477901 [ 0.75220233] [ 0.56330234]\n",
      "27 0.04552 [ 0.75815922] [ 0.54976094]\n",
      "28 0.0433578 [ 0.76397288] [ 0.53654504]\n",
      "29 0.0412983 [ 0.76964682] [ 0.52364689]\n",
      "30 0.0393366 [ 0.77518439] [ 0.51105881]\n",
      "31 0.0374681 [ 0.78058875] [ 0.49877328]\n",
      "32 0.0356883 [ 0.78586322] [ 0.48678312]\n",
      "33 0.0339931 [ 0.79101098] [ 0.47508121]\n",
      "34 0.0323784 [ 0.79603487] [ 0.46366057]\n",
      "35 0.0308404 [ 0.80093813] [ 0.4525145]\n",
      "36 0.0293755 [ 0.80572343] [ 0.44163635]\n",
      "37 0.0279801 [ 0.81039369] [ 0.43101972]\n",
      "38 0.026651 [ 0.81495172] [ 0.42065832]\n",
      "39 0.0253851 [ 0.81940013] [ 0.41054597]\n",
      "40 0.0241793 [ 0.82374161] [ 0.40067673]\n",
      "41 0.0230307 [ 0.82797873] [ 0.39104474]\n",
      "42 0.0219368 [ 0.83211398] [ 0.38164428]\n",
      "43 0.0208947 [ 0.83614987] [ 0.37246984]\n",
      "44 0.0199022 [ 0.84008873] [ 0.36351594]\n",
      "45 0.0189569 [ 0.84393293] [ 0.35477728]\n",
      "46 0.0180564 [ 0.84768462] [ 0.34624866]\n",
      "47 0.0171987 [ 0.85134619] [ 0.33792508]\n",
      "48 0.0163818 [ 0.85491973] [ 0.32980159]\n",
      "49 0.0156036 [ 0.85840732] [ 0.32187337]\n",
      "50 0.0148624 [ 0.8618111] [ 0.31413576]\n",
      "51 0.0141564 [ 0.86513311] [ 0.30658418]\n",
      "52 0.013484 [ 0.86837518] [ 0.29921409]\n",
      "53 0.0128435 [ 0.87153941] [ 0.29202121]\n",
      "54 0.0122334 [ 0.87462747] [ 0.28500119]\n",
      "55 0.0116523 [ 0.87764138] [ 0.27814996]\n",
      "56 0.0110988 [ 0.88058275] [ 0.27146342]\n",
      "57 0.0105716 [ 0.88345349] [ 0.26493764]\n",
      "58 0.0100695 [ 0.88625515] [ 0.2585687]\n",
      "59 0.00959116 [ 0.88898951] [ 0.25235292]\n",
      "60 0.00913557 [ 0.89165813] [ 0.24628654]\n",
      "61 0.00870163 [ 0.89426255] [ 0.24036597]\n",
      "62 0.0082883 [ 0.89680445] [ 0.23458774]\n",
      "63 0.0078946 [ 0.8992852] [ 0.22894841]\n",
      "64 0.00751961 [ 0.90170634] [ 0.22344467]\n",
      "65 0.00716241 [ 0.90406919] [ 0.21807319]\n",
      "66 0.00682219 [ 0.90637535] [ 0.21283089]\n",
      "67 0.00649814 [ 0.90862602] [ 0.20771459]\n",
      "68 0.00618948 [ 0.91082257] [ 0.20272125]\n",
      "69 0.00589547 [ 0.91296631] [ 0.19784796]\n",
      "70 0.00561542 [ 0.91505855] [ 0.19309182]\n",
      "71 0.00534869 [ 0.91710055] [ 0.18845004]\n",
      "72 0.00509461 [ 0.91909331] [ 0.1839198]\n",
      "73 0.00485262 [ 0.92103827] [ 0.17949851]\n",
      "74 0.00462212 [ 0.9229365] [ 0.1751835]\n",
      "75 0.00440256 [ 0.92478901] [ 0.17097221]\n",
      "76 0.00419344 [ 0.92659706] [ 0.16686217]\n",
      "77 0.00399425 [ 0.92836159] [ 0.16285092]\n",
      "78 0.00380452 [ 0.93008375] [ 0.1589361]\n",
      "79 0.00362381 [ 0.93176448] [ 0.15511538]\n",
      "80 0.00345167 [ 0.93340486] [ 0.15138653]\n",
      "81 0.00328772 [ 0.93500572] [ 0.14774728]\n",
      "82 0.00313154 [ 0.93656814] [ 0.14419553]\n",
      "83 0.0029828 [ 0.93809301] [ 0.14072917]\n",
      "84 0.0028411 [ 0.93958122] [ 0.13734615]\n",
      "85 0.00270615 [ 0.9410336] [ 0.13404442]\n",
      "86 0.00257761 [ 0.94245112] [ 0.13082211]\n",
      "87 0.00245516 [ 0.94383454] [ 0.12767722]\n",
      "88 0.00233855 [ 0.94518477] [ 0.12460796]\n",
      "89 0.00222746 [ 0.94650245] [ 0.12161245]\n",
      "90 0.00212166 [ 0.94778848] [ 0.11868897]\n",
      "91 0.00202088 [ 0.94904363] [ 0.11583578]\n",
      "92 0.00192489 [ 0.95026869] [ 0.11305119]\n",
      "93 0.00183346 [ 0.95146412] [ 0.11033347]\n",
      "94 0.00174637 [ 0.95263088] [ 0.10768113]\n",
      "95 0.00166341 [ 0.95376968] [ 0.10509257]\n",
      "96 0.00158439 [ 0.95488095] [ 0.10256619]\n",
      "97 0.00150914 [ 0.95596558] [ 0.10010056]\n",
      "98 0.00143745 [ 0.95702416] [ 0.09769421]\n",
      "99 0.00136917 [ 0.95805722] [ 0.0953457]\n",
      "\n",
      "=== Test ===\n",
      "X:5, Y: [ 4.88563156]\n",
      "X:2.5, Y: [ 2.49048877]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "        \n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X:5, Y:\", sess.run(hypothesis, feed_dict={X:5}))\n",
    "    print(\"X:2.5, Y:\",sess.run(hypothesis, feed_dict={X:2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
